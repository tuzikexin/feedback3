{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import argparse\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold, StratifiedKFold, StratifiedGroupKFold\nimport shutil\nimport time\nimport gc\nimport random\nimport math\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport transformers\nfrom transformers import TrainingArguments, Trainer, DataCollatorForWholeWordMask\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, AutoModel\nfrom torch import nn\nfrom torch.optim import Adam, SGD, AdamW\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, DataCollatorWithPadding\n# imports the torch_xla package\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-17T14:05:53.803078Z","iopub.execute_input":"2022-09-17T14:05:53.803497Z","iopub.status.idle":"2022-09-17T14:05:53.814602Z","shell.execute_reply.started":"2022-09-17T14:05:53.803463Z","shell.execute_reply":"2022-09-17T14:05:53.813538Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/feedback-prize-english-language-learning/test.csv')\n#df = pd.read_csv('../input/add-train/add_train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:05:53.816316Z","iopub.execute_input":"2022-09-17T14:05:53.816604Z","iopub.status.idle":"2022-09-17T14:05:53.833575Z","shell.execute_reply.started":"2022-09-17T14:05:53.816574Z","shell.execute_reply":"2022-09-17T14:05:53.832487Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    model_path = '../input/d/jonathanchan/deberta-v3-large/deberta-v3-large' #  nghuyong/ernie-2.0-large-en studio-ousia/luke-large\n    max_input_length = 1024\n    batch_size = 4\n    seed = 1006\n    num_workers = 2\n    device='cuda'\n    print_freq = 100\n    \nclass Custom_Bert_Simple(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(CFG.model_path)\n        config.num_labels = 6\n        config.max_position_embeddings = CFG.max_input_length\n        config.attention_probs_dropout_prob = 0\n        config.hidden_dropout_prob = 0\n        self.backbone = AutoModelForSequenceClassification.from_config(config=config)\n        \n    def forward(self, input_ids, attention_mask, labels=None):\n        base_output = self.backbone(input_ids=input_ids,\n                                attention_mask=attention_mask,\n                               )\n\n        output = base_output[0]\n        #output = self.cls(self.dropout(output))\n        if labels is None:\n            return output\n        \n        else:\n            return (nn.MSELoss()(output,labels), output)\n        \nclass Custom_Bert_Mean_with_GRU(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(CFG.model_path)\n        config.output_hidden_states = True\n        config.max_position_embeddings = CFG.max_input_length\n        config.attention_probs_dropout_prob = 0\n        config.hidden_dropout_prob = 0\n        self.backbone = AutoModel.from_config(config=config)\n        dim = config.hidden_size\n        # Multidropout\n        self.dropout1 = nn.Dropout(0)  # dropout 0.1\n        self.dropout2 = nn.Dropout(0)  # dropout 0.2\n        self.dropout3 = nn.Dropout(0)  # dropout 0.3\n        self.dropout4 = nn.Dropout(0)  # dropout 0.4\n        self.dropout5 = nn.Dropout(0)  # dropout 0.5\n\n        # GRU\n        self.rnn = nn.GRU(\n            input_size=dim,  # 输入大小\n            hidden_size=dim // 2,  # 隐藏层大小\n            bidirectional=True,  # 双向\n            batch_first=True,  # batch在最前面的维度\n            dropout=0.,  # dropout 0.1\n            num_layers=1  # 层数\n        )\n\n        # Head\n        self.head = nn.Linear(dim, 6)\n        # GRU  # 线性层\n\n        self._init_weights(self.head, config)  # 初始化权重\n\n    def _init_weights(self, module, config):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        base_output = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n\n        output = base_output.last_hidden_state\n        output_backbone = self.rnn(output)[0]  # GRU\n\n        output1 = self.head(self.dropout1(torch.mean(output_backbone, dim=1)))  # dropout 0.1 + 线性层\n        output2 = self.head(self.dropout2(torch.mean(output_backbone, dim=1)))  # dropout 0.2 + 线性层\n        output3 = self.head(self.dropout3(torch.mean(output_backbone, dim=1)))  # dropout 0.3 + 线性层\n        output4 = self.head(self.dropout4(torch.mean(output_backbone, dim=1)))  # dropout 0.4 + 线性层\n        output5 = self.head(self.dropout5(torch.mean(output_backbone, dim=1)))  # dropout 0.5 + 线性层\n\n        output = (output1 + output2 + output3 + output4 + output5) / 5  # 平均\n        #print(output.shape)\n        \n        return output\n\n        ","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:05:53.835724Z","iopub.execute_input":"2022-09-17T14:05:53.836110Z","iopub.status.idle":"2022-09-17T14:05:53.854745Z","shell.execute_reply.started":"2022-09-17T14:05:53.836075Z","shell.execute_reply":"2022-09-17T14:05:53.853448Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, df, tokenizer):\n        #self.labels = df[[\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"]].values\n        self.texts = df['full_text'].values\n        self.tokenizer = tokenizer\n    def classes(self):\n        return self.labels\n\n    def __len__(self):\n        return len(self.texts)\n\n\n    def __getitem__(self, idx):\n\n        text = self.texts[idx]\n\n        output_ids = tokenizer(text,\n                              padding='max_length', max_length=CFG.max_input_length, truncation=True)\n        return torch.as_tensor(output_ids['input_ids'], dtype=torch.long), \\\n               torch.as_tensor(output_ids['attention_mask'], dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:05:53.856059Z","iopub.execute_input":"2022-09-17T14:05:53.856698Z","iopub.status.idle":"2022-09-17T14:05:53.868010Z","shell.execute_reply.started":"2022-09-17T14:05:53.856663Z","shell.execute_reply":"2022-09-17T14:05:53.867021Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:05:53.871384Z","iopub.execute_input":"2022-09-17T14:05:53.871859Z","iopub.status.idle":"2022-09-17T14:05:54.967983Z","shell.execute_reply.started":"2022-09-17T14:05:53.871832Z","shell.execute_reply":"2022-09-17T14:05:54.967001Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def valid_fn(valid_loader, model, device):\n    model.to(device)\n    model.eval()\n    preds = []\n    labels = []\n    start = end = time.time()\n    for step, batch in enumerate(valid_loader):\n        mask = batch[1].to(device)\n        input_ids = batch[0].to(device)\n        with torch.no_grad():\n            y_preds = model(input_ids, mask)\n        preds.append(y_preds.to('cpu').numpy())\n        end = time.time()\n    predictions = np.concatenate(preds)\n    return  predictions","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:05:54.970059Z","iopub.execute_input":"2022-09-17T14:05:54.970556Z","iopub.status.idle":"2022-09-17T14:05:54.977855Z","shell.execute_reply.started":"2022-09-17T14:05:54.970518Z","shell.execute_reply":"2022-09-17T14:05:54.976818Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"va_dataset = TestDataset(df,tokenizer)\nval_loader = DataLoader(va_dataset,\n                              batch_size=CFG.batch_size * 2,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:05:54.979450Z","iopub.execute_input":"2022-09-17T14:05:54.980266Z","iopub.status.idle":"2022-09-17T14:05:55.090908Z","shell.execute_reply.started":"2022-09-17T14:05:54.980230Z","shell.execute_reply":"2022-09-17T14:05:55.089859Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"res = []\n","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:05:55.093970Z","iopub.execute_input":"2022-09-17T14:05:55.094829Z","iopub.status.idle":"2022-09-17T14:05:55.101748Z","shell.execute_reply.started":"2022-09-17T14:05:55.094791Z","shell.execute_reply":"2022-09-17T14:05:55.100761Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    model = Custom_Bert_Mean_with_GRU()\n    model.load_state_dict(torch.load(f'../input/fb-sim/microsoft_deberta-v3-large_gru_best{i}.pth')['model'])\n    prediction = valid_fn(val_loader, model, 'cuda')\n    res.append(prediction)\n    del model","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:05:55.104866Z","iopub.execute_input":"2022-09-17T14:05:55.105547Z","iopub.status.idle":"2022-09-17T14:07:46.666341Z","shell.execute_reply.started":"2022-09-17T14:05:55.105518Z","shell.execute_reply":"2022-09-17T14:07:46.665072Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"res = np.mean(res, axis=0)\nres.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:07:46.667880Z","iopub.execute_input":"2022-09-17T14:07:46.668247Z","iopub.status.idle":"2022-09-17T14:07:46.688376Z","shell.execute_reply.started":"2022-09-17T14:07:46.668211Z","shell.execute_reply":"2022-09-17T14:07:46.687537Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(3, 6)"},"metadata":{}}]},{"cell_type":"code","source":"res = np.where(res<1, 1, res)\nres = np.where(res>5, 5, res)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:07:46.689880Z","iopub.execute_input":"2022-09-17T14:07:46.694668Z","iopub.status.idle":"2022-09-17T14:07:46.702899Z","shell.execute_reply.started":"2022-09-17T14:07:46.694619Z","shell.execute_reply":"2022-09-17T14:07:46.701532Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/feedback-prize-english-language-learning/sample_submission.csv\")\nsubmission.cohesion = res[:, 0]\nsubmission.syntax = res[:, 1]\nsubmission.vocabulary = res[:, 2]\nsubmission.phraseology = res[:, 3]\nsubmission.grammar = res[:, 4]\nsubmission.conventions = res[:, 5]","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:07:46.705453Z","iopub.execute_input":"2022-09-17T14:07:46.708667Z","iopub.status.idle":"2022-09-17T14:07:46.736379Z","shell.execute_reply.started":"2022-09-17T14:07:46.708352Z","shell.execute_reply":"2022-09-17T14:07:46.735405Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:07:46.739098Z","iopub.execute_input":"2022-09-17T14:07:46.741138Z","iopub.status.idle":"2022-09-17T14:07:46.760190Z","shell.execute_reply.started":"2022-09-17T14:07:46.741106Z","shell.execute_reply":"2022-09-17T14:07:46.759109Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n0  0000C359D63E  2.928136  2.749842    3.074777     2.940013  2.561346   \n1  000BAD50D026  2.591225  2.473002    2.687952     2.380739  2.237844   \n2  00367BB2546B  3.481908  3.431592    3.552463     3.583048  3.406031   \n\n   conventions  \n0     2.546719  \n1     2.654334  \n2     3.244173  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>2.928136</td>\n      <td>2.749842</td>\n      <td>3.074777</td>\n      <td>2.940013</td>\n      <td>2.561346</td>\n      <td>2.546719</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>2.591225</td>\n      <td>2.473002</td>\n      <td>2.687952</td>\n      <td>2.380739</td>\n      <td>2.237844</td>\n      <td>2.654334</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>3.481908</td>\n      <td>3.431592</td>\n      <td>3.552463</td>\n      <td>3.583048</td>\n      <td>3.406031</td>\n      <td>3.244173</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:07:46.764470Z","iopub.execute_input":"2022-09-17T14:07:46.767848Z","iopub.status.idle":"2022-09-17T14:07:46.774620Z","shell.execute_reply.started":"2022-09-17T14:07:46.767813Z","shell.execute_reply":"2022-09-17T14:07:46.773529Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}